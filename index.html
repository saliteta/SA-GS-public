<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description"
    content="SA-GS: Semantic-Aware Gaussian Splatting for Large Scene Reconstruction with Geometry Constrain">
  <meta property="og:title"
    content="SA-GS: Semantic-Aware Gaussian Splatting for Large Scene Reconstruction with Geometry Constrain" />
  <meta property="og:description" content="SA-GS" />
  <meta property="og:url" content="<WEB URL>" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->



  <meta name="twitter:title"
    content="SA-GS: Semantic-Aware Gaussian Splatting for Large Scene Reconstruction with Geometry Constrain">
  <meta name="twitter:description"
    content="SA-GS: Semantic-Aware Gaussian Splatting for Large Scene Reconstruction with Geometry Constrain">

  <meta name="twitter:card" content="">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="SA-GS Butian">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>SA-GS</title>
  <link rel="icon" type="image/x-icon" href="static\images\webpage_raw.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="static/css/twentytwenty.css" type="text/css" media="screen" />
  <!-- Optional: Bootstrap JS and its dependencies (jQuery and Popper) -->
  <script src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
  <script src="static/js/jquery.event.move.js" type="text/javascript"></script>
  <script src="static/js/jquery.twentytwenty.js" type="text/javascript"></script>

  <!--<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>-->
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
</head>

<body>

  <style>
    img {
      display: block;
      margin-left: auto;
      margin-right: auto;
      width: 80%;
      margin-top: 20px;
      margin-bottom: 20px;
      /* Adjust this value as needed */

    }



    h2.subtitle.has-text-centered {
      margin-left: 20%;
      /* Adjust the margin as needed */
      margin-right: 20%;
      /* Adjust the margin as needed */
      text-align: center;
    }
  </style>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-fullhd">
        <img src="static/images/CUSZ-03logo-whier.png"
          style="align: left;width:192px;height:160px;position:absolute;margin-left: 100px" />
        <div class="columns is-centered">
          <div class="column has-text-centered">

            <h1 class="title is-1 publication-title">SA-GS</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://saliteta.github.io/">Butian Xiong</a>, Xiaoyu Ye, Tze Ho Elden Tse, Kai Han, Shuguang
                Cui, <a href="https://mypage.cuhk.edu.cn/academics/lizhen/">Zhen Li</a>,</span>

              <div class="is-size-5 publication-authors">
                <!--The Chinese University of Hong Kong, Shenzhen-->
                <span class="author-block">The Chinese University of Hong Kong, Shenzhen</span>
              </div>


              <!-- Supplementary PDF link -->
              <span class="link-block">
                <a href="static/pdfs/SA_GS.pdf" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- ArXiv abstract Link -->
              <span class="link-block">
                <a href="https://arxiv.org/<arXiv Link>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <!-- Code Link -->
              <span class="link-block">
                <a href="https://github.com/<CODE LINK HERE>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>

              <!-- Website Code Link -->
              <span class="link-block">
                <a href="https://github.com/saliteta/SA-GS-public" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Website Repo</span>
                </a>
              </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>



  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-fullhd">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              With the emergence of Gaussian Splats, recent efforts have focused on large-scale scene geometric
              reconstruction. However, most of these efforts either concen- trate on memory reduction or spatial space
              division, neglecting information in the semantic space. In this paper, we propose a novel method, named
              SA-GS, for fine-grained 3D geometry reconstruction using semantic-aware 3D Gaussian Splats. Specifically,
              we leverage prior information stored in large vision models such as SAM and DINO to generate semantic
              masks. We then introduce a geo- metric complexity measurement function to serve as soft regularization,
              guiding the shape of each Gaussian Splat within specific semantic areas. Additionally, we present a method
              that estimates the expected number of Gaussian Splats in different semantic areas, effectively providing a
              lower bound for Gaussian Splats in these areas. Subsequently, we extract the point cloud using a novel
              probability density-based extraction method, transforming Gaussian Splats into a point cloud crucial for
              downstream tasks. Our method also offers the potential for detailed semantic inquiries while maintaining
              high image-based reconstruction results. We provide extensive experiments on publicly available
              large-scale scene reconstruction datasets with highly accurate point clouds as ground truth and our novel
              dataset. Our results demonstrate the superiority of our method over current state-of-the-art Gaussian
              Splats reconstruction methods by a significant margin in terms of geometric-based measurement metrics.
            </p>
            <div class="column is-four-fifths">
            </div>
          </div>
        </div>
  </section>
  <br />
  <!-- End paper abstract -->
  <div class="container is-fullhd">
    <div class="columns is-centered">
      <h2 class="title">Method</h2>
    </div>
  </div>
  <!-- Figure 1 -->
  <div class="container is-fullhd">
    <img src="static/methods_introduction/point_cloud_comparison.jpg" alt="Point Cloud Comparison" />
  </div>
  <div class="container is-fullhd">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          Figure 1: Qualitative comparison between our method and other 3DGS based methods. We proposed Shape
          constrain, alpha constrain and point cloud extraction in the current study. Quantitative ablation is shown
          in the right handside of the figure.
        </div>
      </div>
    </div>
  </div>
  <!--End figure 1-->

  <!-- Figure 2 -->
  <div class="container is-fullhd">
    <img src="static/methods_introduction/NIPS_Teaser (1).jpg" alt="NIPS Teaser" />
  </div>
  <div class="container is-fullhd">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          Figure 2: The blue section of the figure illustrates common methods for reconstructing geometrically
          aligned Gaussian Splats. The input for all Gaussian Splatting methods includes a COLMAP initialization
          consisting of images, camera positions, and SfM sparse point clouds. The output will be a traditional
          representation such as a mesh or point cloud, as shown in the right blue box. During training, in addition
          to the common image rendering loss, most methods encourage all 3D Gaussians to form a disk-like shape. After
          several training iterations, or at the end of the training process, other methods select a hard threshold
          for the alpha value and use the remaining Gaussians for geometric reconstruction. However, these hard
          constraints often result in poorer reconstruction, as demonstrated in our experiments. Instead of
          encouraging all Gaussians to adopt the same shape, our method uses semantic information to control the shape
          in detail. We first produce semantic masks for each input image, then extract shape information for each
          semantic group, and use this information to locally control the shape of each Gaussian. Additionally, we
          provide an opacity field sampling method that can dynamically allocate the desired number of points and
          ignore defective reconstruction parts.

        </div>
      </div>
    </div>
  </div>
  <!--End figure 2-->

  <!-- Figure 3 -->

  <div class="container is-fullhd">
    <img src="static/methods_introduction/Fantasy_Surface.jpg" alt="Fantasy Surface" />
  </div>
  <div class="container is-fullhd">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          Figure 3: Explanation of fantasy-surace probelmIn the first row of this figure, we display the results of
          using SuGaR to reconstruct the Campus and College scenes from GauUsceneV2. Many surfaces incorrectly model
          the lighting conditions due to complex effects, such as how glass reflects sunlight at different angles and
          how clouds block sunlight. These imaginary surfaces that do not represent the true surface are regarded as
          fantasy surfaces. Our method, shown in the bottom rows, largely alleviates this problem, as evident in the
          figure. Another major source of geometric error occurs at the edges of unbounded scenes. However, this issue
          is common to all methods due to the sparsity of images at the edges and is not the focus of our current
          work.

        </div>
      </div>
    </div>
  </div>
  <!--End figure 3-->

  <!-- Figure 4 -->

  <div class="container is-fullhd">
    <img src="static/methods_introduction/Inconsistancy.jpg" alt="Inconsistancy" />
  </div>
  <div class="container is-fullhd">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          Figure 4: Explanation of Inconsistency problem. The semantic segmentation results are sometimes inconsistent
          with previous judgments. As shown in Figures (a) and (b), two tunnels are regarded as ground using
          GroundingSAM. However, in the images captured from a camera position immediately adjacent to them (Figures (c)
          and (d)), the left tunnel is not regarded as ground. This inconsistency between consecutive images is the
          primary cause of failure in naive reconstruction methods.
        </div>
      </div>
    </div>
  </div>
  <!--End figure 4-->
  <!-- Figure 5 -->

  <div class="container is-fullhd">
    <img src="static/methods_introduction/Methods.jpg" alt="Methods" />
  </div>
  <div class="container is-fullhd">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          Figure 5: Method Overview: Our method pipeline consists of three main stages. Initially, we utilize the same
          input as vanilla Gaussian Splatting, but enhance it with semantic information extracted via Grounding SAM.
          Next, we assess the geometric complexity of each semantic group by calculating high-frequency power. Our
          geometric constraint is implemented through a soft regularization, facilitated by a semantic loss function.
          This guides the Gaussian shapes to match the expected shapes determined earlier. The rendering loss further
          refines the shape and attributes of the 3DGS, while the shape constraint, indicated by a negative sign,
          ensures alignment between rendered and real images. Controlling the shapes of different 3DGS is achieved by
          mapping their projected pixels onto the semantic map obtained earlier. Additionally, by reducing the number of
          low-opacity Gaussian splats to the expected count, we minimize GPU memory consumption during training.
          Finally, we offer a user-friendly point cloud extraction method via hierarchical probability density sampling.
          Initially, we create a multinomial distribution using the opacity values stored in each 3DGS. Then, based on
          user inputs and the multinomial distribution, we determine the number of points to sample from each Gaussian
          distribution. Detailed experimental results demonstrate significant improvements at each step, showcasing
          superior geometric reconstruction compared to current state-of-the-art methods.
        </div>
      </div>
    </div>
  </div>
  <!--End figure 5-->
  <!-- Figure 6 -->

  <div class="container is-fullhd">
    <img src="static/methods_introduction/Rendering_Comparison.jpg" alt="Rendering Comparison" />
  </div>
  <div class="container is-fullhd">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          Figure 6: This the comparison between our method and vanilla Gaussian Splats. As one can see that from the
          figure shown above, our methods largely sharpening the edge of image. The tower shown in the figure (a) merges
          together and sharpened in our method, while in (b) figures, we eliminate the noise around the high building.
          While for the last group of pictures shows that our steadily alpha decreasing strategy is successful.
        </div>
      </div>
    </div>
  </div>
  <!--End figure 6-->
  <script>
    var left_images = ["SUGAR.JPG", "3DGS.JPG", "NERFACTO.JPG", "INSTANTNGP.JPG"];
    var right_images = ["SAM_GS_ALPHA.JPG", "SAM_GS_SHAPE_ONLY.JPG", "EXTRACTED_POINT_ALPHA.JPG", "EXTRACTED_POINT_SHAPE_ONLY.JPG"];
    var folders = ["CUHK_LOWER", "CUHK_UPPER", "HAV", "LFLS", "SMBU", "SZIIT"];
    var locations = ["CUHK-SZ Lower Campus", "CUHK-SZ Upper Campus", "HAV", "LFLS", "SMBU", "SZIIT"];
    var lefts = ["SuGaR", "Vanilla GS", "Nerfacto", "Instant NGP"];
    var rights = ["SAM-GS Alpha", "SAM-GS Shape Only", "Extracted Point Alpha", "Extracted Point Shape Only"];
    var location_index = 0, left_index = 0, right_index = 0;


    function update_location() {
      const selectBox = document.getElementById("location_option");
      location_index = selectBox.selectedIndex;
      document.getElementById("position").innerText = locations[location_index];
      document.getElementById("path_left").src = "static/visualization_pc_jpg/" + folders[location_index] + "/" + left_images[left_index];
      document.getElementById("path_right").src = "static/visualization_pc_jpg/" + folders[location_index] + "/" + right_images[right_index];
    }

    function update_left() {
      const selectBox = document.getElementById("left_option");
      left_index = selectBox.selectedIndex;
      document.getElementById("path_left").src = "static/visualization_pc_jpg/" + folders[location_index] + "/" + left_images[left_index];
      $(function () {
        $(".twentytwenty-container").twentytwenty({
          default_offset_pct: 0.3, // How much of the before image is visible when the page loads
          orientation: 'horizontal', // Orientation of the before and after images ('horizontal' or 'vertical')
          before_label: lefts[left_index], // Set a custom before label
          after_label: rights[right_index], // Set a custom after label 
          click_to_move: true // Allow a user to click (or tap) anywhere on the image to move the slider to that location.
        });
      });
    }

    function update_right() {
      const selectBox = document.getElementById("right_option");
      right_index = selectBox.selectedIndex;
      document.getElementById("path_right").src = "static/visualization_pc_jpg/" + folders[location_index] + "/" + right_images[right_index];
      $(function () {
        $(".twentytwenty-container").twentytwenty({
          default_offset_pct: 0.3, // How much of the before image is visible when the page loads
          orientation: 'horizontal', // Orientation of the before and after images ('horizontal' or 'vertical')
          before_label: lefts[left_index], // Set a custom before label
          after_label: rights[right_index], // Set a custom after label 
          click_to_move: true // Allow a user to click (or tap) anywhere on the image to move the slider to that location.
        });
      });
    }
  </script>
  <div class="container is-fullhd">
    <div class="columns is-centered">
      <h2 class="title">Comparison</h2>
    </div>
  </div>
  <br />
  <div class="container is-fullhd">
    <div class="columns is-centered has-text-centered">
      <div class="table-container">
        <div class="content">
          <table>
            <tr>
              <th width="20%">Location</th>
              <th width="40%">Left-Hand Side</th>
              <th width="40%">Right-Hand Side</th>
            </tr>
            <tr>
              <td>
                <select name="Location" id="location_option" onchange="update_location()">
                  <option value=0>CUHK-SZ Lower Campus</option>
                  <option value=1>CUHK-SZ Upper Campus</option>
                  <option value=2>HAV</option>
                  <option value=3>LFLS</option>
                  <option value=4>SMBU</option>
                  <option value=5>SZIIT</option>
                </select>
              </td>
              <td>
                <select name="Left-Hand Side" id="left_option" onchange="update_left()">
                  <option value=0>SuGaR</option>
                  <option value=1>Vanilla GS</option>
                  <option value=2>Nerfacto</option>
                  <option value=3>Instant NGP</option>
                </select>
              </td>
              <td>
                <select name="Right-Hand Side" id="right_option" onchange="update_right()">
                  <option value=0>SAM-GS Alpha</option>
                  <option value=1>SAM-GS Shape Only</option>
                  <option value=2>Extracted Point Alpha</option>
                  <option value=3>Extracted Point Shape Only</option>
                </select>
              </td>
            </tr>
          </table>
        </div>
      </div>
    </div>
  </div>
  <br />
  <div class="container is-fullhd">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="twentytwenty-container">
          <!-- The before image is first -->
          <img id="path_left" src="static/visualization_pc_jpg/CUHK_LOWER/SUGAR.JPG"
            style="width: 100%; margin-top: 0;" />
          <!-- The after image is last -->
          <img id="path_right" src="static/visualization_pc_jpg/CUHK_LOWER/SAM_GS_ALPHA.JPG"
            style="width: 100%; margin-top: 0;" />
        </div>
      </div>
    </div>
  </div>

  <div class="container is-fullhd">
    <div class="columns is-centered has-text-centered">
      <h3 class="is-size-5">
        <b>Location: </b>
        <b id="position">CUHK-SZ Lower Campus</b>
      </h3>
    </div>
  </div>
  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-fullhd">
      <div class="columns is-centered">
        <h2 class="title">BibTex</h2>
      </div>
      <pre><code>
        BibTex here.
      </code></pre>
    </div>
  </section>
  <!--End BibTex citation -->

  <section class="section" id="BibTeX">
    <div class="container is-fullhd">
      <div class="columns is-centered">
        <h2 class="title">Acknowledgement</h2>
      </div>
      This website is mainly constructed and maintained by <a href="https://fzhwenzhou.github.io">Zihao Fang</a>. If
      there is
      any issue about the website, please email <a
        href="mailto:zihaofang1@link.cuhk.edu.cn">zihaofang1@link.cuhk.edu.cn</a>, or directly open an issue at the
      website's github repository.
    </div>
  </section>



  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the of this website, we just ask that you link back to this page in the footer.
              <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <script>
    $(function () {
      $(".twentytwenty-container").twentytwenty({
        default_offset_pct: 0.3, // How much of the before image is visible when the page loads
        orientation: 'horizontal', // Orientation of the before and after images ('horizontal' or 'vertical')
        before_label: lefts[left_index], // Set a custom before label
        after_label: rights[right_index], // Set a custom after label 
        click_to_move: true // Allow a user to click (or tap) anywhere on the image to move the slider to that location.
      });
    });
  </script>
  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>